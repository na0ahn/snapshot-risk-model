# scripts/inference_teacher_on_skku.py

import os
import sys
import pickle
from typing import List

import torch
import pandas as pd
from torch.utils.data import DataLoader
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€ (ì§ì ‘ ì‹¤í–‰í•´ë„ import ë˜ë„ë¡)
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from datasets.snapshot_dataset import SnapshotDataset
from models.snapshot_risk_model import SnapshotRiskModelFT
from configs.feature_config import NUMERIC_COLS, CAT_COLS, LABEL_COL, GROUP_COLS

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ê²½ë¡œ ìƒìˆ˜
SKKU_SNAPSHOT_PATH = os.path.join("data", "skku", "processed", "skku_snapshots.csv")
SKKU_SNAPSHOT_WITH_TEACHER_PATH = os.path.join(
    "data", "skku", "processed", "skku_snapshots_with_teacher.csv"
)
TEACHER_CHECKPOINT_PATH = os.path.join("checkpoints", "teacher_oulad.pt")
ENCODER_PATH = os.path.join("checkpoints", "cat_encoders.pkl")


def run_inference_teacher_on_skku():
    print(f"[Device] {DEVICE}")

    # ---------------------------------------------------
    # 1. Teacher ìª½ì—ì„œ í•™ìŠµí•´ ë‘” ì¹´í…Œê³ ë¦¬ ì¸ì½”ë” ë¡œë“œ
    # ---------------------------------------------------
    if not os.path.exists(ENCODER_PATH):
        raise FileNotFoundError(f"[ERR] Encoder íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")

    with open(ENCODER_PATH, "rb") as f:
        cat_encoders = pickle.load(f)
    print(f"[OK] Encoders ë¡œë“œ ì™„ë£Œ. Keys: {list(cat_encoders.keys())}")

    # Teacher ê¸°ì¤€ ì¹´ë””ë„ë¦¬í‹°(embedding í¬ê¸°)ë¥¼ ê³ ì •
    #  -> Teacherê°€ í•™ìŠµí•œ ì¹´í…Œê³ ë¦¬ ê³µê°„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    teacher_cardinalities: List[int] = [len(cat_encoders[c]) for c in CAT_COLS]
    print(f"[Info] Teacher cardinalities: {dict(zip(CAT_COLS, teacher_cardinalities))}")

    # ---------------------------------------------------
    # 2. SKKU snapshot CSV ë¡œë“œ â†’ Dataset êµ¬ì„±
    # ---------------------------------------------------
    if not os.path.exists(SKKU_SNAPSHOT_PATH):
        raise FileNotFoundError(f"[ERR] SKKU snapshot CSVê°€ ì—†ìŠµë‹ˆë‹¤: {SKKU_SNAPSHOT_PATH}")

    dataset = SnapshotDataset(
        csv_path=SKKU_SNAPSHOT_PATH,
        numeric_cols=NUMERIC_COLS,
        cat_cols=CAT_COLS,
        label_col=LABEL_COL,
        group_cols=GROUP_COLS,
        teacher_prob_col=None,         # ì•„ì§ ì—†ìŒ
        fit_encoders=False,            # Teacher ì¸ì½”ë” ì¬ì‚¬ìš©
        cat_encoders=cat_encoders,
    )

    loader = DataLoader(
        dataset,
        batch_size=512,
        shuffle=False,   # ìˆœì„œë¥¼ ìœ ì§€í•´ì•¼ teacher_probë¥¼ ê·¸ëŒ€ë¡œ ë¶™ì¼ ìˆ˜ ìˆìŒ
        num_workers=0,
    )

    print(f"[Dataset] SKKU snapshots loaded. n_samples = {len(dataset)}")

    # ---------------------------------------------------
    # 3. Teacher ëª¨ë¸ ì´ˆê¸°í™” & ê°€ì¤‘ì¹˜ ë¡œë“œ
    #    â­ì¤‘ìš”: cat_cardinalitiesëŠ” 'Teacher ê¸°ì¤€'ìœ¼ë¡œ ì„¸íŒ…í•´ì•¼ í•¨
    # ---------------------------------------------------
    if not os.path.exists(TEACHER_CHECKPOINT_PATH):
        raise FileNotFoundError(f"[ERR] Teacher ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤: {TEACHER_CHECKPOINT_PATH}")

    model = SnapshotRiskModelFT(
        num_numeric=len(NUMERIC_COLS),
        cat_cardinalities=teacher_cardinalities,
        d_token=32,
        n_heads=4,
        n_layers=3,
        dim_feedforward=128,
        dropout=0.1,
    ).to(DEVICE)

    try:
        state = torch.load(TEACHER_CHECKPOINT_PATH, map_location=DEVICE)
        model.load_state_dict(state)
    except RuntimeError as e:
        print("[Fatal] Teacher state_dict ë¡œë“œ ì‹¤íŒ¨ (Embedding í¬ê¸° ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±)")
        print(e)
        return

    model.eval()
    print("[OK] Teacher ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ---------------------------------------------------
    # 4. Inference loop â†’ teacher_prob ë¦¬ìŠ¤íŠ¸ ìƒì„±
    #    ğŸ”’ clamp: SKKUì—ì„œ ìƒˆë¡œ ë“±ì¥í•œ ì¹´í…Œê³ ë¦¬(UNK)ë¥¼ ë²”ìœ„ ì•ˆìœ¼ë¡œ ë§ì¶”ê¸°
    # ---------------------------------------------------
    all_probs = []

    with torch.no_grad():
        for batch in tqdm(loader, desc="Teacher inference on SKKU"):
            numeric = batch["numeric"].to(DEVICE)
            categorical = batch["categorical"].to(DEVICE)

            # ê° ë²”ì£¼í˜• í”¼ì²˜ë³„ë¡œ indexë¥¼ [0, card-1] ë²”ìœ„ë¡œ clamp
            #  - SnapshotDatasetì—ì„œ UNKëŠ” len(mapping)ìœ¼ë¡œ í• ë‹¹ë˜ì–´ ìˆìŒ
            #  - TeacherëŠ” len(mapping)ê¹Œì§€ë§Œ embeddingì„ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ
            #    UNKë¥¼ ë§ˆì§€ë§‰ ìœ íš¨ index(card-1)ë¡œ "ë¶™ì—¬"ì¤€ë‹¤.
            for i, card in enumerate(teacher_cardinalities):
                categorical[:, i] = categorical[:, i].clamp(max=card - 1)

            _, probs = model(numeric, categorical)  # (B,)
            all_probs.extend(probs.cpu().tolist())

    # ê¸¸ì´ ì²´í¬
    if len(all_probs) != len(dataset):
        raise RuntimeError(
            f"[ERR] teacher_prob ê¸¸ì´ ë¶ˆì¼ì¹˜: probs={len(all_probs)}, dataset={len(dataset)}"
        )

    # ---------------------------------------------------
    # 5. ì›ë³¸ SKKU snapshot CSVì— teacher_prob ì—´ ì¶”ê°€í•´ì„œ ì €ì¥
    # ---------------------------------------------------
    df = pd.read_csv(SKKU_SNAPSHOT_PATH)
    df["teacher_prob"] = all_probs

    os.makedirs(os.path.dirname(SKKU_SNAPSHOT_WITH_TEACHER_PATH), exist_ok=True)
    df.to_csv(SKKU_SNAPSHOT_WITH_TEACHER_PATH, index=False)
    print(f"[Done] Teacher inference ê²°ê³¼ ì €ì¥ â†’ {SKKU_SNAPSHOT_WITH_TEACHER_PATH}")


if __name__ == "__main__":
    run_inference_teacher_on_skku()
